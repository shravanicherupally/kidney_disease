{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91c030de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 1: Import Required Libraries ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99aca3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned dataset loaded. (3000, 7)\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 2: Load Cleaned Data ---\n",
    "df = pd.read_csv(\"../Data/cleaned_ckd_data.csv\")\n",
    "print(\"‚úÖ Cleaned dataset loaded.\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e11177fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Features and target selected\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 3: Define Features and Target ---\n",
    "X = df[['age', 'sc', 'hemo', 'al', 'bp', 'sg']]\n",
    "y = df['classification']\n",
    "print(\"‚úÖ Features and target selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a8cd5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data split into train and test sets\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 4: Train-Test Split ---\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "print(\"‚úÖ Data split into train and test sets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd5dc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5: Define Models and Hyperparameters ---\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\"C\": [0.1, 1, 10]},\n",
    "    \"SVM\": {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]},\n",
    "    \"Random Forest\": {\"n_estimators\": [50, 100]},\n",
    "    \"AdaBoost\": {\"n_estimators\": [50, 100]},\n",
    "    \"Gradient Boosting\": {\"n_estimators\": [50, 100]}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb7faf76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Tuning Logistic Regression...\n",
      "\n",
      "üîç Tuning SVM...\n",
      "\n",
      "üîç Tuning Random Forest...\n",
      "\n",
      "üîç Tuning AdaBoost...\n",
      "\n",
      "üîç Tuning Gradient Boosting...\n",
      "\n",
      "‚úÖ All models evaluated.\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Evaluate and Tune Models ---\n",
    "results = []\n",
    "best_models = {}\n",
    "\n",
    "for name in models:\n",
    "    print(f\"\\nüîç Tuning {name}...\")\n",
    "    grid = GridSearchCV(models[name], param_grids[name], cv=5, scoring='f1', n_jobs=-1)\n",
    "    grid.fit(X_train, y_train)\n",
    "    best_model = grid.best_estimator_\n",
    "    best_models[name] = best_model\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    y_prob = best_model.predict_proba(X_test)[:, 1] if hasattr(best_model, \"predict_proba\") else None\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else 0\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1 Score\": f1,\n",
    "        \"AUC\": auc\n",
    "    })\n",
    "\n",
    "print(\"\\n‚úÖ All models evaluated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec4d5d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Comparison:\n",
      "                 Model  Accuracy  Precision  Recall  F1 Score  AUC\n",
      "0  Logistic Regression       1.0        1.0     1.0       1.0  1.0\n",
      "1                  SVM       1.0        1.0     1.0       1.0  1.0\n",
      "2        Random Forest       1.0        1.0     1.0       1.0  1.0\n",
      "3             AdaBoost       1.0        1.0     1.0       1.0  1.0\n",
      "4    Gradient Boosting       1.0        1.0     1.0       1.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 7: Compare and Display Results ---\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"F1 Score\", ascending=False).reset_index(drop=True)\n",
    "print(\"\\nüìä Model Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90feadff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Best model 'Logistic Regression' saved to ../App/model/model.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 8: Save the Best Model ---\n",
    "import joblib\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = best_models[best_model_name]\n",
    "joblib.dump(best_model, \"../App/model/model.pkl\")\n",
    "print(f\"\\n‚úÖ Best model '{best_model_name}' saved to ../App/model/model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
